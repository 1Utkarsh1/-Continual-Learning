2025-03-10 23:26:05,445 - __main__ - INFO - Starting Continual Learning experiment
2025-03-10 23:26:05,445 - __main__ - INFO - Arguments: Namespace(method='baseline', tasks='mnist_split', model='simple_cnn', epochs=5, batch_size=64, learning_rate=0.001, lambda_ewc=5000, fisher_sample_size=200, buffer_size=500, replay_batch_size=32, temperature=2.0, alpha=1.0, seed=42, device=None, eval_freq=1, save_dir='results')
2025-03-10 23:26:05,448 - __main__ - INFO - Using device: cpu
2025-03-10 23:26:05,449 - __main__ - INFO - Task sequence: ['mnist_0_4', 'mnist_5_9']
2025-03-10 23:26:05,449 - src.data.data_loader - INFO - Loading task mnist_0_4 (dataset: mnist, classes: [0, 1, 2, 3, 4])
2025-03-10 23:26:33,270 - src.data.data_loader - INFO - Loaded task mnist_0_4 with 27537 training, 3059 validation, and 5139 test samples
2025-03-10 23:26:33,271 - src.data.data_loader - INFO - Loading task mnist_5_9 (dataset: mnist, classes: [5, 6, 7, 8, 9])
2025-03-10 23:26:33,316 - src.data.data_loader - INFO - Loaded task mnist_5_9 with 26464 training, 2940 validation, and 4861 test samples
2025-03-10 23:26:33,325 - src.models.model_factory - INFO - Created simple_cnn model with input shape torch.Size([1, 28, 28]) and 5 output classes
2025-03-10 23:26:33,326 - __main__ - INFO - Starting training on task 1/2: mnist_0_4
2025-03-10 23:27:31,606 - src.methods.baseline - INFO - Task 1 - Epoch 1/5: Train Loss: 0.1076, Train Acc: 96.27%, Val Loss: 0.0239, Val Acc: 99.15%
2025-03-10 23:28:29,398 - src.methods.baseline - INFO - Task 1 - Epoch 2/5: Train Loss: 0.0236, Train Acc: 99.28%, Val Loss: 0.0255, Val Acc: 99.28%
2025-03-10 23:29:27,271 - src.methods.baseline - INFO - Task 1 - Epoch 3/5: Train Loss: 0.0148, Train Acc: 99.53%, Val Loss: 0.0198, Val Acc: 99.44%
2025-03-10 23:30:24,558 - src.methods.baseline - INFO - Task 1 - Epoch 4/5: Train Loss: 0.0119, Train Acc: 99.63%, Val Loss: 0.0255, Val Acc: 99.18%
2025-03-10 23:31:22,322 - src.methods.baseline - INFO - Task 1 - Epoch 5/5: Train Loss: 0.0083, Train Acc: 99.75%, Val Loss: 0.0211, Val Acc: 99.58%
2025-03-10 23:31:22,322 - src.methods.baseline - INFO - Loaded best model for task 1 with validation loss: 0.0198
2025-03-10 23:31:38,202 - __main__ - INFO - After task 1, accuracy on task 1: 99.86%
2025-03-10 23:31:38,202 - __main__ - INFO - Starting training on task 2/2: mnist_5_9
2025-03-10 23:31:51,157 - __main__ - ERROR - Experiment failed with error: Target 8 is out of bounds.
Traceback (most recent call last):
  File "C:\Users\kumar\Desktop\github\continual_learning\src\main.py", line 302, in main
    run_continual_learning(args, logger)
  File "C:\Users\kumar\Desktop\github\continual_learning\src\main.py", line 245, in run_continual_learning
    learner.train(
  File "C:\Users\kumar\Desktop\github\continual_learning\src\methods\baseline.py", line 92, in train
    loss = self.criterion(outputs, targets)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kumar\AppData\Roaming\Python\Python312\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kumar\AppData\Roaming\Python\Python312\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kumar\AppData\Roaming\Python\Python312\site-packages\torch\nn\modules\loss.py", line 1188, in forward
    return F.cross_entropy(input, target, weight=self.weight,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kumar\AppData\Roaming\Python\Python312\site-packages\torch\nn\functional.py", line 3104, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
IndexError: Target 8 is out of bounds.
